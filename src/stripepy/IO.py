# Copyright (C) 2024 Andrea Raffo <andrea.raffo@ibv.uio.no>
#
# SPDX-License-Identifier: MIT

import datetime
import functools
import json
import pathlib
from importlib.metadata import version
from typing import Any, Dict, List, Optional, Sequence, Tuple, Union

import h5py
import hictkpy
import numpy as np
import numpy.typing as npt
import pandas as pd
from pandas.testing import assert_frame_equal

from stripepy.utils.stripe import Stripe


class Result(object):
    """
    A class used to represent the results generated by stripepy call.

    Attributes
    ----------
    chrom: Tuple[str, int]
        name and length of the chromosomes to which the Result instance belongs to
    empty: bool
        check whether any stripe has been registered with the Result instance
    roi: Optional[Dict[str, List[int]]]
        the region of interest associated with the Result instance
    min_persistence: float
        the minimum persistence used during computation
    """

    def __init__(self, chrom_name: str, chrom_size: int):
        """
        Parameters
        ----------

        chrom: str
            chromosome name
        """
        assert chrom_size > 0

        self._chrom = (chrom_name, chrom_size)
        self._roi = None
        self._min_persistence = None

        self._ut_all_minimum_points = None
        self._ut_all_maximum_points = None
        self._ut_persistence_of_all_minimum_points = None
        self._ut_persistence_of_all_maximum_points = None

        self._lt_all_minimum_points = None
        self._lt_all_maximum_points = None
        self._lt_persistence_of_all_minimum_points = None
        self._lt_persistence_of_all_maximum_points = None

        self._ut_persistent_minimum_points = None
        self._ut_persistent_maximum_points = None
        self._ut_persistence_of_minimum_points = None
        self._ut_persistence_of_maximum_points = None
        self._ut_pseudodistribution = None

        self._lt_persistent_minimum_points = None
        self._lt_persistent_maximum_points = None
        self._lt_persistence_of_minimum_points = None
        self._lt_persistence_of_maximum_points = None
        self._lt_pseudodistribution = None

        self._ut_stripes = None
        self._lt_stripes = None

    @property
    def _valid_attributes(self) -> List[str]:
        """
        Get the list of valid attributes
        """
        return [a.removeprefix("_lt_") for a in dir(self) if a.startswith("_lt_")]

    @property
    def empty(self) -> bool:
        return self._lt_stripes is None and self._ut_stripes is None

    @property
    def chrom(self) -> Tuple[str, int]:
        return self._chrom

    @property
    def roi(self) -> Optional[Dict[str, List[int]]]:
        return self._roi

    @property
    def min_persistence(self) -> float:
        if self._min_persistence is None:
            raise RuntimeError('Attribute "min_persistence" is not set')

        return self._min_persistence

    def get(self, name: str, location: str) -> Union[List[Stripe], npt.NDArray[int], npt.NDArray[float]]:
        """
        Get the value associated with the given attribute name and location.

        Parameters
        ----------
        name: str
            name of the attribute to be fetched
        location: str
            location of the attribute to be fetched. Should be "LT" or "UT"

        Returns
        -------
        attribute
            the value associated with the given name and location.
        """
        if location == "lower":
            location = "LT"
        elif location == "upper":
            location = "UT"
        elif location not in {"LT", "UT"}:
            raise ValueError("Location should be UT or LT")

        attr_name = f"_{location.lower()}_{name}"
        if not hasattr(self, attr_name):
            raise AttributeError(
                f"No attribute named \"{name}\". Valid attributes are: {', '.join(self._valid_attributes)}"
            )

        attr = getattr(self, attr_name)
        if name == "stripes" and attr is None:
            return []

        if attr is None:
            raise RuntimeError(f'Attribute "{name}" for "{location}" is not set')

        return attr

    def get_stripes_descriptor(self, descriptor: str, location: str) -> Union[npt.NDArray[float], npt.NDArray[int]]:
        """
        Get the stripe descriptor for the given location.

        Parameters
        ----------
        descriptor: str
            name of the descriptor to be fetched
        location: str
            location of the attribute to be fetched. Should be "LT" or "UT"

        Returns
        -------
        descriptor
            the value associated with the given descriptor and location.
        """
        if location not in {"LT", "UT"}:
            raise ValueError("Location should be UT or LT")

        if not hasattr(Stripe, descriptor):
            raise AttributeError(f'Stripe instance does not have an attribute named "{descriptor}"')

        stripes = self.get("stripes", location)

        if descriptor in {"seed", "left_bound", "right_bound", "top_bound", "bottom_bound"}:
            dtype = int
        else:
            dtype = float

        return np.array([getattr(stripe, descriptor) for stripe in stripes], dtype=dtype)

    def get_stripe_geo_descriptors(self, location: str) -> pd.DataFrame:
        """
        Fetch all geometric descriptors at once.

        Parameters
        ----------
        location: str
            location of the attribute to be fetched. Should be "LT" or "UT"

        Returns
        -------
        descriptors
            the table with the geometric descriptors associated with the Result instance
        """
        descriptors = [
            "seed",
            "top_persistence",
            "left_bound",
            "right_bound",
            "top_bound",
            "bottom_bound",
        ]

        return pd.DataFrame(
            {descriptor: self.get_stripes_descriptor(descriptor, location) for descriptor in descriptors}
        )

    def get_stripe_bio_descriptors(self, location: str) -> pd.DataFrame:
        """
        Fetch all biological descriptors at once.

        Parameters
        ----------
        location: str
            location of the attribute to be fetched. Should be "LT" or "UT"

        Returns
        -------
        descriptors
            the table with the biological descriptors associated with the Result instance
        """
        descriptors = [
            "inner_mean",
            "outer_mean",
            "rel_change",
            "inner_std",
        ]

        return pd.DataFrame(
            {descriptor: self.get_stripes_descriptor(descriptor, location) for descriptor in descriptors}
        )

    def set_roi(self, coords: Dict[str, List[int]]):
        """
        Set the region of interest (RoI) for the current Result instance.

        Parameters
        ----------
        coords: Dict[str, List[int]]
            a dictionary with the coordinates of the region of interest.
            The dictionary should contain two keys: "genomic" and "matrix".
            The value associated with the "genomic" key should be a list of 4 integers
            representing the genomic coordinates of the region of interest.
            The value associated with the "matrix" key should be a list of 4 integers
            representing the matrix coordinates of the region of interest.
        """
        if self._roi is not None:
            raise RuntimeError("roi has already been set")

        self._roi = coords

    def set_min_persistence(self, min_persistence: float):
        """
        Set the minimum persistence used during computation.

        Parameters
        ----------
        min_persistence: float
        """
        if self._min_persistence is not None:
            raise RuntimeError("min_persistence has already been set")

        self._min_persistence = min_persistence

    def set(
        self,
        name: str,
        data: Union[Sequence[int], Sequence[float], Sequence[Stripe]],
        location: str,
        force: bool = False,
    ):
        """
        Set the attribute corresponding to the given attribute name and location.

        Parameters
        ----------
        name: str
           name of the attribute to be set.
           Supported attributes are:
              * all_minimum_points
              * all_maximum_points
              * persistence_of_all_minimum_points
              * persistence_of_all_maximum_points
              * persistent_minimum_points
              * persistent_maximum_points
              * persistence_of_minimum_points
              * persistence_of_maximum_points
              * pseudodistribution
              * stripes

        data:
            data to be registered with the Result instance
        location: str
            location of the attribute to be registered. Should be "LT" or "UT"
        force: bool
            force overwrite existing values
        """
        if location == "lower":
            location = "LT"
        elif location == "upper":
            location = "UT"
        elif location not in {"LT", "UT"}:
            raise ValueError("Location should be UT or LT")

        attr_name = f"_{location.lower()}_{name}"
        if not hasattr(self, attr_name):
            raise AttributeError(
                f"No attribute named \"{name}\". Valid attributes are: {', '.join(self._valid_attributes)}"
            )

        if not force and getattr(self, attr_name) is not None:
            raise RuntimeError(f'Attribute "{name}" for {location} has already been set')

        setattr(self, attr_name, np.array(data))


class ResultFile(object):
    """
    A class used to read and write StripePy results to a HDF5 file.

    Attributes
    ----------
    path: pathlib.Path
        the path to the opened file
    assembly: str
        the name of the reference genome assembly used to generate the file
    resolution: int
        the resolution of the Hi-C matrix used to generate the file
    creation_date: datetime.datetime
        the file creation date
    format: str
        the file format string
    format_url: str
        the URL where the file format is documented
    format_version: int
        the format version of the file currently opened
    generated_by: str
        the name of the tool used to generate the opened file
    normalization: Optional[str]
        the name of the normalization used to generate the data stored in the given file
    chromosomes: Dict[str, int]
        the chromosomes associated with the opened file

    """

    def __init__(self, path: pathlib.Path, mode: str = "r"):
        if mode not in ["r", "w", "a"]:
            raise ValueError('mode should be "r", "w", or "a"')

        self._path = path
        self._mode = mode
        self._chroms = None

        self._h5 = h5py.File(self._path, self._mode)

        if self._mode != "w":
            self._validate(self._h5)
            self._chroms = {
                chrom.decode("utf-8"): size for chrom, size in zip(self._h5["/chroms/name"], self._h5["/chroms/length"])
            }
            self._version = self._h5.attrs["format-version"]
        else:
            self._version = 2

        self._attrs = dict(self._h5.attrs)

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self._h5.close()

    def __getitem__(self, chrom: str) -> Result:
        if chrom not in self._chroms:
            raise KeyError(f'chromosome "{chrom}" not found')

        res = Result(chrom, self._chroms[chrom])
        res.set_min_persistence(self.get_min_persistence(chrom))
        for location in ("LT", "UT"):
            res.set(
                "all_minimum_points", self.get(chrom, "all_minimum_points", location)["all_minimum_points"], location
            )
            res.set(
                "all_maximum_points", self.get(chrom, "all_maximum_points", location)["all_maximum_points"], location
            )
            res.set(
                "persistence_of_all_minimum_points",
                self.get(chrom, "persistence_of_all_minimum_points", location)["persistence_of_all_minimum_points"],
                location,
            )
            res.set(
                "persistence_of_all_maximum_points",
                self.get(chrom, "persistence_of_all_maximum_points", location)["persistence_of_all_maximum_points"],
                location,
            )
            res.set(
                "pseudodistribution", self.get(chrom, "pseudodistribution", location)["pseudodistribution"], location
            )

            df = self.get(chrom, "stripes", location)

            stripes = []

            cols = [
                "seed",
                "left_bound",
                "right_bound",
                "top_bound",
                "bottom_bound",
                "top_persistence",
                "inner_mean",
                "inner_std",
                "outer_lmean",
                "outer_rmean",
                "quartile",
            ]
            for col in cols:
                if col not in df:
                    if col == "quartile":
                        df[col] = pd.Series(list(np.full(5, np.nan)))
                    else:
                        df[col] = np.nan

            if location == "LT":
                location_ = "lower_triangular"
            else:
                location_ = "upper_triangular"

            for (
                seed,
                left_bound,
                right_bound,
                top_bound,
                bottom_bound,
                top_persistence,
                inner_mean,
                inner_std,
                outer_lmean,
                outer_rmean,
                quartile,
            ) in df[cols].itertuples(index=False):
                s = Stripe(
                    seed=seed,
                    top_pers=top_persistence,
                    horizontal_bounds=(left_bound, right_bound),
                    vertical_bounds=(top_bound, bottom_bound),
                    where=location_,
                )
                s.set_biodescriptors(
                    inner_mean=inner_mean,
                    inner_std=inner_std,
                    outer_lmean=outer_lmean,
                    outer_rmean=outer_rmean,
                    five_number=quartile,
                )
                stripes.append(s)

            res.set("stripes", stripes, location)

        return res

    @property
    def path(self) -> pathlib.Path:
        return self._path

    @functools.cached_property
    def assembly(self) -> str:
        return self._h5.attrs["assembly"]

    @functools.cached_property
    def resolution(self) -> int:
        return int(self._h5.attrs["bin-size"])

    @functools.cached_property
    def creation_date(self) -> datetime.datetime:
        return datetime.datetime.fromisoformat(self._h5.attrs["creation-date"])

    @functools.cached_property
    def format(self) -> str:
        return self._h5.attrs["format"]

    @functools.cached_property
    def format_url(self) -> str:
        return self._h5.attrs["format-url"]

    @functools.cached_property
    def format_version(self) -> int:
        return self._h5.attrs["format-version"]

    @functools.cached_property
    def generated_by(self) -> str:
        return self._h5.attrs["generated-by"]

    @functools.cached_property
    def metadata(self) -> Dict[str, Any]:
        return json.loads(self._h5.attrs["metadata"])

    @functools.cached_property
    def normalization(self) -> Optional[str]:
        norm = self._h5.attrs["normalization"]
        if norm == "NONE":
            return None
        return norm

    @property
    def chromosomes(self) -> Dict[str, int]:
        return self._chroms

    @staticmethod
    def _validate(h5: h5py.File):
        """
        Perform a basic sanity check on the metadata of the current file
        """
        format = h5.attrs.get("format")  # noqa
        format_version = h5.attrs.get("format-version")
        try:
            if format is None:
                raise RuntimeError('attribute "format" is missing')

            if format_version is None:
                raise RuntimeError('attribute "format-version" is missing')

            if format != "HDF5::StripePy":
                raise RuntimeError(f'unrecognized file format: expected "HDF5::StripePy", found "{format}"')

            known_versions = {1, 2}
            if format_version not in known_versions:
                known_versions_ = ", ".join(str(v) for v in known_versions)
                raise RuntimeError(
                    f'unsupported file format version "{format_version}". At present only versions {known_versions_} are supported'
                )
        except RuntimeError as e:
            raise RuntimeError(
                f'failed to validate input file "{h5.filename}": {e}: file is corrupt or was not generated by StripePy.'
            )

    def _get_min_persistence_v1(self, chrom: str) -> float:
        return float(self._h5[f"/{chrom}/global-pseudo-distributions"].attrs["min_persistence_used"])

    @functools.cache
    def _read_min_persistence_values(self) -> Dict[str, float]:
        values = self._h5["/min_persistence"][:]
        if len(values) != len(self._chroms):
            raise RuntimeError(
                f"min_persistence vector has an unexpected length: expected {len(self._chroms)}, found {len(values)}"
            )
        return {chrom: float(pers) for chrom, pers in zip(self._chroms, values)}

    def _get_min_persistence_v2(self, chrom: str) -> float:
        return self._read_min_persistence_values()[chrom]

    def get_min_persistence(self, chrom: str) -> float:
        """
        Get the minimum persistence associated with the given chromosome.

        Parameters
        ----------
        chrom: str
            chromosome name

        Returns
        -------
            the minimum persistence
        """
        if chrom not in self._chroms:
            raise KeyError(f'File "{self.path}" does not have data for chromosome "{chrom}"')

        if self._version == 1:
            return self._get_min_persistence_v1(chrom)
        return self._get_min_persistence_v2(chrom)

    def _get_v1(self, chrom: str, field: str, location: str) -> pd.DataFrame:
        mappings = {
            "pseudodistribution": f"/{chrom}/global-pseudo-distributions/{location}/pseudo-distribution",
            "all_minimum_points": f"/{chrom}/global-pseudo-distributions/{location}/minima_pts_and_persistence",
            "persistence_of_all_minimum_points": f"/{chrom}/global-pseudo-distributions/{location}/minima_pts_and_persistence",
            "all_maximum_points": f"/{chrom}/global-pseudo-distributions/{location}/maxima_pts_and_persistence",
            "persistence_of_all_maximum_points": f"/{chrom}/global-pseudo-distributions/{location}/maxima_pts_and_persistence",
            "geo_descriptors": f"/{chrom}/stripes/{location}/geo-descriptors",
            "bio_descriptors": f"/{chrom}/stripes/{location}/bio-descriptors",
            "stripes": None,
        }

        if field not in mappings:
            raise KeyError(f"Unknown field \"{field}\". Valid fields are {', '.join(mappings.keys())}")

        if field == "stripes":
            df1 = self._get_v1(chrom, "geo_descriptors", location)
            df2 = self._get_v1(chrom, "bio_descriptors", location)
            return pd.concat((df1, df2), axis="columns")

        path = mappings[field]

        if field not in {"geo_descriptors", "bio_descriptors"}:
            data = self._h5[path][:]
            if field.startswith("persistence"):
                data = data[1, :]
            elif field.endswith("points"):
                data = data[0, :].astype(int)
            return pd.DataFrame({field: data})

        df = pd.DataFrame(data=self._h5[path], columns=self._h5[path].attrs["col_names"])

        if field == "geo_descriptors":
            df = df.rename(
                columns={
                    "seed persistence": "top_persistence",
                    "L-boundary": "left_bound",
                    "R_boundary": "right_bound",
                    "U-boundary": "top_bound",
                    "D-boundary": "bottom_bound",
                }
            )
            for col in ("seed", "left_bound", "right_bound", "top_bound", "bottom_bound"):
                df[col] = df[col].astype(int)
            return df

        return df.rename(
            columns={
                "inner mean": "inner_mean",
                "outer mean": "outer_mean",
                "relative change": "rel_change",
                "standard deviation": "inner_std",
            }
        )

    @functools.cache
    def _read_index(self, name: str, location: str) -> npt.NDArray[int]:
        return self._h5[f"/index/{location.lower()}/{name}"][:].astype(int)

    @functools.cache
    def _index_chromosomes(self) -> Dict[str, int]:
        return {chrom: i for i, chrom in enumerate(self._chroms)}

    def _get_v2(self, chrom: str, field: str, location: str) -> pd.DataFrame:
        known_fields = {
            "pseudodistribution",
            "all_minimum_points",
            "persistence_of_all_minimum_points",
            "all_maximum_points",
            "persistence_of_all_maximum_points",
            "geo_descriptors",
            "bio_descriptors",
            "stripes",
        }

        if field not in known_fields:
            raise KeyError(f"Unknown field \"{field}\". Valid fields are {', '.join(known_fields)}")

        if field == "stripes":
            df1 = self._get_v2(chrom, "geo_descriptors", location)
            df2 = self._get_v2(chrom, "bio_descriptors", location)
            return pd.concat((df1, df2), axis="columns")

        chrom_id = self._index_chromosomes()[chrom]

        if field == "pseudodistribution":
            i1, i2 = self._read_index("chrom_offsets_pd", location)[chrom_id : chrom_id + 2]
            return pd.DataFrame(
                data=self._h5[f"/pseudodistribution/{location.lower()}"][i1:i2].astype(float),
                columns=["pseudodistribution"],
            )

        if field == "all_minimum_points":
            i1, i2 = self._read_index("chrom_offsets_min_points", location)[chrom_id : chrom_id + 2]
            return pd.DataFrame(
                data=self._h5[f"/min_points/{location.lower()}/points"][i1:i2].astype(int),
                columns=["all_minimum_points"],
            )

        if field == "persistence_of_all_minimum_points":
            i1, i2 = self._read_index("chrom_offsets_min_points", location)[chrom_id : chrom_id + 2]
            return pd.DataFrame(
                data=self._h5[f"/min_points/{location.lower()}/persistence"][i1:i2].astype(float),
                columns=["persistence_of_all_minimum_points"],
            )

        if field == "all_maximum_points":
            i1, i2 = self._read_index("chrom_offsets_max_points", location)[chrom_id : chrom_id + 2]
            return pd.DataFrame(
                data=self._h5[f"/max_points/{location.lower()}/points"][i1:i2].astype(int),
                columns=["all_maximum_points"],
            )

        if field == "persistence_of_all_maximum_points":
            i1, i2 = self._read_index("chrom_offsets_max_points", location)[chrom_id : chrom_id + 2]
            return pd.DataFrame(
                data=self._h5[f"/max_points/{location.lower()}/persistence"][i1:i2].astype(float),
                columns=["persistence_of_all_maximum_points"],
            )

        if field == "geo_descriptors":
            i1, i2 = self._read_index("chrom_offsets_stripes", location)[chrom_id : chrom_id + 2]
            return pd.DataFrame(
                data={
                    "seed": self._h5[f"/stripes/{location.lower()}/seed"][i1:i2].astype(int),
                    "top_persistence": self._h5[f"/stripes/{location.lower()}/top_persistence"][i1:i2].astype(float),
                    "left_bound": self._h5[f"/stripes/{location.lower()}/left_bound"][i1:i2].astype(int),
                    "right_bound": self._h5[f"/stripes/{location.lower()}/right_bound"][i1:i2].astype(int),
                    "top_bound": self._h5[f"/stripes/{location.lower()}/top_bound"][i1:i2].astype(int),
                    "bottom_bound": self._h5[f"/stripes/{location.lower()}/bottom_bound"][i1:i2].astype(int),
                }
            )

        if field == "bio_descriptors":
            i1, i2 = self._read_index("chrom_offsets_stripes", location)[chrom_id : chrom_id + 2]
            outer_lmean = self._h5[f"/stripes/{location.lower()}/outer_lmean"][i1:i2].astype(float)
            outer_rmean = self._h5[f"/stripes/{location.lower()}/outer_rmean"][i1:i2].astype(float)
            quartile = self._h5[f"/stripes/{location.lower()}/quartile"][i1:i2, :].astype(float)

            assert quartile.shape[1] == 5

            df = pd.DataFrame(
                data={
                    "inner_mean": self._h5[f"/stripes/{location.lower()}/inner_mean"][i1:i2].astype(float),
                    "inner_std": self._h5[f"/stripes/{location.lower()}/inner_std"][i1:i2].astype(float),
                    "outer_lmean": outer_lmean,
                    "outer_rmean": outer_rmean,
                    "outer_mean": (outer_lmean + outer_rmean) / 2,
                    "min": quartile[:, 0],
                    "q1": quartile[:, 1],
                    "q2": quartile[:, 2],
                    "q3": quartile[:, 3],
                    "max": quartile[:, 4],
                }
            )

            df.loc[outer_lmean == -1, "outer_mean"] = -1

            df["rel_change"] = np.abs(df["inner_mean"] - df["outer_mean"]) / df["outer_mean"] * 100
            df.loc[df["outer_mean"] <= 0, "rel_change"] = -1.0

            return df

    def get(self, chrom: Optional[str], field: str, location: str) -> pd.DataFrame:
        """
        Get the data associated with the given chromosome, field, and location.

        Parameters
        ----------
        chrom: Optional[str]
            chromosome name.
            when not provided, return data for the entire genome.
        field: str
            name of the field to be fetched.
            Supported names:
                * pseudodistribution
                * all_minimum_points
                * persistence_of_all_minimum_points
                * all_maximum_points
                * persistence_of_all_maximum_points
                * geo_descriptors
                * bio_descriptors
        location: str
            location of the attribute to be registered. Should be "LT" or "UT"

        Returns
        -------
            the data associated with the given chromosome, field, and location
        """
        if chrom is None:
            dfs = []
            for chrom in self._chroms:
                df = self.get(chrom, field, location)
                df["chrom"] = chrom
                dfs.append(df)

            df = pd.concat(dfs).reset_index()
            df["chrom"] = df["chrom"].astype("category")
            cols = df.columns.tolist()
            cols.insert(0, cols.pop(cols.index("chrom")))

            return df[cols]

        if chrom not in self._chroms:
            raise KeyError(f'File "{self.path}" does not have data for chromosome "{chrom}"')

        if location not in {"LT", "UT"}:
            raise ValueError("Location should be UT or LT")

        if self._version == 1:
            return self._get_v1(chrom, field, location)
        return self._get_v2(chrom, field, location)

    def _init_attributes(self, matrix_file: hictkpy.File, normalization: Optional[str], metadata: Dict[str, Any]):
        if normalization is None:
            normalization = "NONE"

        self._h5.attrs["assembly"] = matrix_file.attributes().get("assembly", "unknown")
        self._h5.attrs["bin-size"] = matrix_file.resolution()
        self._h5.attrs["creation-date"] = datetime.datetime.now().isoformat()
        self._h5.attrs["format"] = "HDF5::StripePy"
        self._h5.attrs["format-url"] = "https://github.com/paulsengroup/StripePy"
        self._h5.attrs["format-version"] = 2
        self._h5.attrs["generated-by"] = f"StripePy v{version('stripepy-hic')}"
        self._h5.attrs["metadata"] = json.dumps(metadata, indent=2)
        self._h5.attrs["normalization"] = normalization

    def _init_chromosomes(self, matrix_file: hictkpy.File):
        self._chroms = matrix_file.chromosomes(include_ALL=False)
        self._h5.create_group("/chroms")
        self._h5.create_dataset("/chroms/name", data=list(self._chroms.keys()))
        self._h5.create_dataset("/chroms/length", data=list(self._chroms.values()))

    def _init_index(self):
        templates = [
            "/index/{{location}}/chrom_offsets_pd",
            "/index/{{location}}/chrom_offsets_min_points",
            "/index/{{location}}/chrom_offsets_max_points",
            "/index/{{location}}/chrom_offsets_stripes",
        ]

        for pattern in templates:
            self._h5.create_dataset(
                name=pattern.replace("{{location}}", "lt"),
                data=[0],
                maxshape=(len(self._chroms) + 1),
            )
            self._h5.create_dataset(
                name=pattern.replace("{{location}}", "ut"),
                data=[0],
                maxshape=(len(self._chroms) + 1),
            )

    def _init_min_persistence(self):
        self._h5.create_dataset(name="/min_persistence", dtype=float, shape=(0,), maxshape=(len(self._chroms),))

    def _init_pseudodistribution(self, compression_lvl: int):
        resolution = self.resolution
        maxshape = sum((length + resolution - 1) // resolution for length in self._chroms.values())
        self._h5.create_dataset(
            name="/pseudodistribution/lt",
            dtype=float,
            shape=(0,),
            maxshape=(maxshape,),
            compression="gzip",
            compression_opts=compression_lvl,
            shuffle=True,
        )
        self._h5.create_dataset(
            name="/pseudodistribution/ut",
            dtype=float,
            shape=(0,),
            maxshape=(maxshape,),
            compression="gzip",
            compression_opts=compression_lvl,
            shuffle=True,
        )

    def _init_points(self, compression_lvl: int):
        params = {
            "compression": "gzip",
            "compression_opts": compression_lvl,
            "shuffle": True,
            "chunks": True,
            "maxshape": (None,),
            "shape": (0,),
        }

        templates = {
            "/min_points/{{location}}/points": params | {"dtype": int},
            "/min_points/{{location}}/persistence": params | {"dtype": float},
            "/max_points/{{location}}/points": params | {"dtype": int},
            "/max_points/{{location}}/persistence": params | {"dtype": float},
        }

        for pattern, params in templates.items():
            dsets = {pattern.replace("{{location}}", "lt"), pattern.replace("{{location}}", "ut")}
            for name in dsets:
                self._h5.create_dataset(name=name, **params)

    def _init_stripes(self, compression_lvl: int):
        params = {
            "compression": "gzip",
            "compression_opts": compression_lvl,
            "shuffle": True,
            "chunks": True,
            "maxshape": (None,),
            "shape": (0,),
        }

        templates = {
            "/stripes/{{location}}/seed": params | {"dtype": int},
            "/stripes/{{location}}/left_bound": params | {"dtype": int},
            "/stripes/{{location}}/right_bound": params | {"dtype": int},
            "/stripes/{{location}}/top_bound": params | {"dtype": int},
            "/stripes/{{location}}/bottom_bound": params | {"dtype": int},
            "/stripes/{{location}}/top_persistence": params | {"dtype": float},
            "/stripes/{{location}}/inner_mean": params | {"dtype": float},
            "/stripes/{{location}}/inner_std": params | {"dtype": float},
            "/stripes/{{location}}/outer_lmean": params | {"dtype": float},
            "/stripes/{{location}}/outer_rmean": params | {"dtype": float},
            "/stripes/{{location}}/quartile": params | {"dtype": float, "shape": (0, 0), "maxshape": (None, 5)},
        }

        for pattern, params in templates.items():
            dsets = {pattern.replace("{{location}}", "lt"), pattern.replace("{{location}}", "ut")}
            for name in dsets:
                self._h5.create_dataset(name=name, **params)

    def init_file(
        self,
        matrix_file: hictkpy.File,
        normalization: Optional[str],
        metadata: Dict[str, Any],
        compression_lvl: int = 9,
    ):
        """
        Initialize the current file.

        This method must be called when opening a ResultFile for writing before adding data to the file.

        Parameters
        ----------
        matrix_file: hictkpy.File
            handle of the file that is used to compute the results stored in this file
        normalization: Optional[str]
            name of the normalization used to compute the results stored in this file
        metadata: Dict[str, Any]
            dictionary with the metadata to be associated with this file.
            The dictionary should contain values that can be encoded as a JSON string
        compression_lvl: int
            GZIP compression level used to create large HDF5 datasets
        """
        if normalization is None:
            normalization = "NONE"

        self._init_attributes(matrix_file, normalization, metadata)
        self._init_chromosomes(matrix_file)
        self._init_index()
        self._init_min_persistence()
        self._init_points(compression_lvl)
        self._init_pseudodistribution(compression_lvl)
        self._init_stripes(compression_lvl)

    def _append_to_dset(self, path: str, data):
        if len(data) == 0:
            return

        dset = self._h5[path]

        shape = list(dset.maxshape)
        shape[0] = dset.shape[0] + len(data)

        dset.resize(shape)
        dset[-len(data) :] = data

    def _append_min_persistence(self, pers: float):
        self._append_to_dset("/min_persistence", (pers,))

    def _append_pseudodistribution(self, data: Sequence[float], location: str):
        location = location.lower()
        assert location in {"lt", "ut"}

        self._append_to_dset(f"/pseudodistribution/{location}", data)
        self._append_to_dset(
            f"/index/{location}/chrom_offsets_pd", (self._h5[f"/pseudodistribution/{location}"].shape[0],)
        )

    def _append_persistence(self, points: Sequence[int], persistence: Sequence[float], kind: str, location: str):
        location = location.lower()
        assert len(points) == len(persistence)
        assert kind in {"min", "max"}
        assert location in {"lt", "ut"}

        self._append_to_dset(f"{kind}_points/{location}/points", points)
        self._append_to_dset(f"{kind}_points/{location}/persistence", persistence)
        self._append_to_dset(
            f"/index/{location}/chrom_offsets_{kind}_points",
            (self._h5[f"{kind}_points/{location}/persistence"].shape[0],),
        )

    def _append_stripes(self, stripes: Sequence[Stripe], location: str):
        location = location.lower()
        assert location in {"lt", "ut"}
        seeds = np.empty_like(stripes, dtype=int)
        left_bounds = np.empty_like(stripes, dtype=int)
        right_bounds = np.empty_like(stripes, dtype=int)
        top_bounds = np.empty_like(stripes, dtype=int)
        bottom_bounds = np.empty_like(stripes, dtype=int)
        top_persistence_values = np.empty_like(stripes, dtype=float)
        inner_means = np.empty_like(stripes, dtype=float)
        inner_stds = np.empty_like(stripes, dtype=float)
        outer_lmeans = np.empty_like(stripes, dtype=float)
        outer_rmeans = np.empty_like(stripes, dtype=float)
        quartiles = np.empty((len(stripes), 5), dtype=float)

        for i, s in enumerate(stripes):
            seeds[i] = s.seed
            left_bounds[i] = s.left_bound
            right_bounds[i] = s.right_bound
            top_bounds[i] = s.top_bound
            bottom_bounds[i] = s.bottom_bound
            top_persistence_values[i] = s.top_persistence
            inner_means[i] = s.inner_mean
            inner_stds[i] = s.inner_std
            outer_lmeans[i] = s.outer_lmean
            outer_rmeans[i] = s.outer_rmean
            quartiles[i] = s.five_number

        self._append_to_dset(f"/stripes/{location}/seed", seeds)
        self._append_to_dset(f"/stripes/{location}/left_bound", left_bounds)
        self._append_to_dset(f"/stripes/{location}/right_bound", right_bounds)
        self._append_to_dset(f"/stripes/{location}/top_bound", top_bounds)
        self._append_to_dset(f"/stripes/{location}/bottom_bound", bottom_bounds)
        self._append_to_dset(f"/stripes/{location}/top_persistence", top_persistence_values)
        self._append_to_dset(f"/stripes/{location}/inner_mean", inner_means)
        self._append_to_dset(f"/stripes/{location}/inner_std", inner_stds)
        self._append_to_dset(f"/stripes/{location}/outer_lmean", outer_lmeans)
        self._append_to_dset(f"/stripes/{location}/outer_rmean", outer_rmeans)
        self._append_to_dset(f"/stripes/{location}/quartile", quartiles)

        offset = self._h5[f"/stripes/{location}/seed"].shape[0]
        self._append_to_dset(f"/index/{location}/chrom_offsets_stripes", (offset,))

    def write_descriptors(self, result: Result):
        """
        Read the descriptors from the given Result object and write them to the opened file.

        Parameters
        ----------
        result: Result
            results to be added to the opened file
        """
        self._append_min_persistence(result.min_persistence)

        for location in ("LT", "UT"):
            self._append_pseudodistribution(result.get("pseudodistribution", location), location)
            self._append_persistence(
                result.get("all_minimum_points", location),
                result.get("persistence_of_all_minimum_points", location),
                "min",
                location,
            )
            self._append_persistence(
                result.get("all_maximum_points", location),
                result.get("persistence_of_all_maximum_points", location),
                "max",
                location,
            )
            self._append_stripes(result.get("stripes", location), location)


def _compare_result_file_attributes(f1: ResultFile, f2: ResultFile, raise_on_exception: bool) -> Dict[str, Any]:
    result = {"success": True, "errors": []}
    try:
        for attr in ("assembly", "resolution", "format", "normalization", "chromosomes"):
            expected = getattr(f1, attr)
            found = getattr(f2, attr)

            if expected != found:
                result["errors"].append(
                    f'mismatched value for attribute "{attr}": expected "{expected}", found "{found}"'
                )
                result["success"] = False

        expected = f1.metadata
        found = f2.metadata

        expected.pop("min-chromosome-size")
        found.pop("min-chromosome-size")

        if expected != found:
            result["errors"].append(
                f'mismatched value for attribute "metadata": expected "{expected}", found "{found}"'
            )
            result["success"] = False

    except Exception as e:
        if raise_on_exception:
            raise
        result["success"] = False
        result["errors"].append(str(e))

    return result


def _compare_result_field(
    f1: ResultFile, f2: ResultFile, chrom: str, field: str, location: str, raise_on_exception: bool
) -> Dict[str, Any]:
    assert chrom in f1.chromosomes
    df1 = f1.get(chrom, field, location)
    try:
        df2 = f2.get(chrom, field, location)
        assert_frame_equal(df1, df2, check_exact=False)
    except Exception as e:
        if raise_on_exception:
            raise
        return {"field": field, "success": False, "errors": [str(e)]}

    return {"field": field, "success": True, "errors": []}


def _compare_result(
    f1: ResultFile, f2: ResultFile, chrom: str, location: str, raise_on_exception: bool
) -> Dict[str, Any]:
    fields = (
        "pseudodistribution",
        "all_minimum_points",
        "persistence_of_all_minimum_points",
        "all_maximum_points",
        "persistence_of_all_maximum_points",
        "stripes",
    )

    report = {"success": True}

    for field in fields:
        field_report = _compare_result_field(f1, f2, chrom, field, location, raise_on_exception)
        field_report.pop("field")
        report[field] = field_report

    for status in report.values():
        if not isinstance(status, dict):
            continue

        if not status["success"]:
            report["success"] = False  # noqa
            break

    return report


def compare_result_files(
    reference: pathlib.Path,
    found: pathlib.Path,
    chroms: Optional[Sequence[str]] = None,
    raise_on_exception: bool = False,
) -> Dict[str, Any]:
    report = {"success": True, "exception": None, "chroms": {}}

    try:
        with ResultFile(reference) as f1, ResultFile(found) as f2:
            report["attributes"] = _compare_result_file_attributes(f1, f2, raise_on_exception)
            report["success"] = report["attributes"]["success"]
            if not report["success"]:
                return report

            if chroms is None:
                chroms = f1.chromosomes

            for chrom in chroms:
                report["chroms"][chrom] = {
                    "LT": _compare_result(f1, f2, chrom, "LT", raise_on_exception),
                    "UT": _compare_result(f1, f2, chrom, "UT", raise_on_exception),
                }
                if not report["chroms"][chrom]["LT"]["success"] or not report["chroms"][chrom]["UT"]["success"]:
                    report["success"] = False

    except Exception as e:
        if raise_on_exception:
            raise
        report["exception"] = str(e)
        report["success"] = False

    return report
